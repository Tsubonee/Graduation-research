{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lB57AkI_nAq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwnc0fA1eZHf",
        "outputId": "b85e6e65-310f-4b17-c7ba-80e190ca25eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ts_ensemble_sunspot'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 176 (delta 0), reused 1 (delta 0), pack-reused 173\u001b[K\n",
            "Receiving objects: 100% (176/176), 140.39 MiB | 23.44 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n",
            "Filtering content: 100% (10/10), 708.68 MiB | 68.32 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yd1008/ts_ensemble_sunspot.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y6hH82EgCFZ",
        "outputId": "2b5d8f72-c7eb-4855-d94e-061f5cccec5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.2.0-cp38-cp38-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray) (2.25.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray) (6.0)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.17.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray) (22.2.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.51.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray) (3.9.0)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray) (2.6.2)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (5.10.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (4.0.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.12.0)\n",
            "Installing collected packages: distlib, virtualenv, ray\n",
            "Successfully installed distlib-0.3.6 ray-2.2.0 virtualenv-20.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ts_ensemble_sunspot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FhNEcHoiJLw",
        "outputId": "65bad4e3-a274-44bf-d7c9-233a95f52a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ts_ensemble_sunspot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost==1.5.1 ray==1.9.0 ray[tune]==1.9.0 torch==1.9.0 numpy==1.20.3 pandas==1.1.4 matplotlib==3.4.2 seaborn==0.11.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DCialOrkid1",
        "outputId": "bf07ca3b-bc56-4370-ee1f-0c5cb6040b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost==1.5.1\n",
            "  Downloading xgboost-1.5.1-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray==1.9.0\n",
            "  Downloading ray-1.9.0-cp38-cp38-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.1.4\n",
            "  Downloading pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.4.2\n",
            "  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn==0.11.2 in /usr/local/lib/python3.8/dist-packages (0.11.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost==1.5.1) (1.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (3.9.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (4.3.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (22.2.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (1.51.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (1.0.4)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.4.2-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.8/237.8 KB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (6.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (3.19.6)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (0.8.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray==1.9.0) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0) (4.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.1.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==1.1.4) (2022.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.4.2) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.4.2) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.4.2) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.4.2) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.4) (1.15.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from redis>=3.5.0->ray==1.9.0) (4.0.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray==1.9.0) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray==1.9.0) (5.10.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray==1.9.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray==1.9.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray==1.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray==1.9.0) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray==1.9.0) (3.12.0)\n",
            "Installing collected packages: torch, redis, numpy, tensorboardX, pandas, matplotlib, xgboost, ray\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: ray\n",
            "    Found existing installation: ray 2.2.0\n",
            "    Uninstalling ray-2.2.0:\n",
            "      Successfully uninstalled ray-2.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.1.4 which is incompatible.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.4.2 numpy-1.20.3 pandas-1.1.4 ray-1.9.0 redis-4.4.2 tensorboardX-2.5.1 torch-1.9.0 xgboost-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ts_ensemble_sunspot/code/Informer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r39qsDh9yWbE",
        "outputId": "8c08a537-08c4-4f46-d14c-c8bf0bdf3bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ts_ensemble_sunspot/code/Informer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title install cuda10.0\n",
        "\n",
        "# # download data\n",
        "# !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "# !sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "# !rm /etc/apt/sources.list.d/cuda.list\n",
        "# !sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "# !sudo apt-get update\n",
        "# !wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "# !sudo apt install -y ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "# !sudo apt-get update\n",
        "\n",
        "# # install NVIDIA driver\n",
        "# !sudo apt-get -y installnvidia-driver-418\n",
        "\n",
        "# # install cuda10.0\n",
        "# !sudo apt-get install -y \\\n",
        "#     cuda-10-0 \\\n",
        "#     libcudnn7=7.6.2.24-1+cuda10.0  \\\n",
        "#     libcudnn7-dev=7.6.2.24-1+cuda10.0\n",
        "\n",
        "# # install TensorRT\n",
        "# !sudo apt-get install -y libnvinfer5=5.1.5-1+cuda10.0 \\\n",
        "#     libnvinfer-dev=5.1.5-1+cuda10.0\n",
        "\n",
        "# !apt --fix-broken install"
      ],
      "metadata": {
        "id": "vYUR0r8Ey7UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "変更した場所  \n",
        "data82行目のパス  \n",
        "resultの342行目のデータの形\n",
        "seedを外す  "
      ],
      "metadata": {
        "id": "tBhwN-6R5Z0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    val_result = val_result.numpy()\n",
        "    val_result = val_result.reshape(-1, 1)\n",
        "    val_result = scaler.inverse_transform(val_result)\n",
        "\n",
        "    test_result = test_result.numpy()\n",
        "    test_result = test_result.reshape(-1,1)\n",
        "    test_result = scaler.inverse_transform(test_result)\n",
        "    train_result = train_result.numpy()\n",
        "    train_result = train_result.reshape(-1,1)\n",
        "    train_result = scaler.inverse_transform(train_result)\n",
        "    truth = truth.numpy()\n",
        "    truth = truth.reshape(-1,1)\n",
        "    truth = scaler.inverse_transform(truth)\n",
        "    train_truth = train_truth.numpy()\n",
        "    train_truth = train_truth.reshape(-1,1)\n",
        "    train_truth = scaler.inverse_transform(train_truth)\n",
        "    val_truth = val_truth.numpy()\n",
        "    val_truth = val_truth.reshape(-1,1)\n",
        "    val_truth = scaler.inverse_transform(val_truth)"
      ],
      "metadata": {
        "id": "ib2bP3Dk7FnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python informer_result.py --use_pre_trained --use_nasa_test_range --pre_trained_file_name /content/ts_ensemble_sunspot/trained_models/best_informer.pth"
      ],
      "metadata": {
        "id": "4ddVopAe1DXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3756a32-e9b9-42fd-f97f-a38ffaf8742a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch version:  1.9.0+cu102\n",
            "Config: {'d_model': 512, 'n_heads': 4, 'e_layers': 2, 'd_layers': 4, 'd_ff': 512, 'window_size': 192, 'dropout': 0.2, 'lr': 0.0001, 'optim_step': 10, 'lr_decay': 0.75, 'factor': 9, 'batch_size': 128}\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "RMSE: 28.35032569119577, MAE: 21.528738021850586 \n",
            " RMSE_first_window: 30.082524028962812, MAE_first_window: 23.273210525512695 \n",
            " RMSE_after_first_window: 23.83923025027824, MAE_after_first_window: 17.55230140686035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "318  \n",
        "    test_result = test_result.numpy()\n",
        "    test_result = test_result.reshape(-1,1)\n",
        "    test_result = scaler.inverse_transform(test_result)\n",
        "    truth = truth.numpy()\n",
        "    truth = truth.reshape(-1,1)\n",
        "    truth = scaler.inverse_transform(truth)"
      ],
      "metadata": {
        "id": "8BG7-wU-DXSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ts_ensemble_sunspot/code/Transformer/transformer_result.py --use_pre_trained --use_nasa_test_range --pre_trained_file_name /content/ts_ensemble_sunspot/trained_models/best_transformer.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIiZDg7n_-ts",
        "outputId": "c74f45d5-9015-41cc-b3be-aee863e35ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Curent config is: {'feature_size': 216, 'num_enc_layers': 3, 'num_dec_layers': 3, 'num_head': 8, 'd_ff': 1024, 'dropout': 0.1, 'lr': 0.0005, 'window_size': 192, 'batch_size': 256, 'optim_step': 2, 'lr_decay': 0.95}\n",
            "Loading pre-trained file: /content/ts_ensemble_sunspot/trained_models/best_transformer.pth\n",
            "RMSE: 33.989582934288485, MAE: 25.564525604248047 \n",
            " RMSE_first_window: 38.396656399434704, MAE_first_window: 28.81987762451172 \n",
            " RMSE_after_first_window: 19.758170839969125, MAE_after_first_window: 17.60877227783203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ts_ensemble_sunspot/code/LSTM/lstm_result.py  --use_pre_trained --use_nasa_test_range --pre_trained_file_name /content/ts_ensemble_sunspot/trained_models/best_lstm.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-qABgP6CmKO",
        "outputId": "1267a4a1-8a86-4c92-d03a-ebde4d580602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 46.144781073405255, MAE: 39.43996810913086 \n",
            " RMSE_first_window: 46.377442658042284, MAE_first_window: 38.35641098022461 \n",
            " RMSE_after_first_window: 45.30788769629412, MAE_after_first_window: 41.543792724609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ts_ensemble_sunspot/code/GRU/gru_result.py --use_pre_trained --use_nasa_test_range --pre_trained_file_name /content/ts_ensemble_sunspot/trained_models/best_gru.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO_itMi6H9Nc",
        "outputId": "98c78963-d68e-4f74-e344-b1e11ac1fdc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 37.13832259112967, MAE: 26.779006958007812 \n",
            " RMSE_first_window: 43.80808365312702, MAE_first_window: 34.84294891357422 \n",
            " RMSE_after_first_window: 9.622260954879007, MAE_after_first_window: 7.576081275939941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ts_ensemble_sunspot/code/XGBoost_ensemble/xgboost_ensemble.py --test_pre_trained_file_name /content/ts_ensemble_sunspot/trained_models/xgboost_dl.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btq4k8wD5ji5",
        "outputId": "b5f41f7e-6e81-4bc2-b86f-1dd587a48024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 23.764895466488618, MAE: 19.33899188573237\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#!/bin/bash python\n",
        "import torch\n",
        "from torch.utils import tensorboard\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import argparse\n",
        "from informer import Informer\n",
        "from utils import *\n",
        "\n",
        "\n",
        "def process_one_batch(batch_x, batch_y):\n",
        "        batch_x = batch_x.float().to(device)\n",
        "        batch_y = batch_y.float().to(device)\n",
        "\n",
        "        dec_inp = torch.zeros([batch_y.shape[0], 1, batch_y.shape[-1]]).float().to(device)\n",
        "        dec_inp = torch.cat([batch_y[:,:(window_size-1),:], dec_inp], dim=1).float().to(device)\n",
        "        outputs = model(batch_x, dec_inp)\n",
        "\n",
        "        return outputs, batch_y\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model,data_loader,criterion, scaler):\n",
        "    torch.cuda.manual_seed\n",
        "    torch.cuda.manual_seed_all  \n",
        "    torch.manual_seed\n",
        "\n",
        "    model.eval()\n",
        "    test_rollout = torch.Tensor(0)   \n",
        "    test_result = torch.Tensor(0)  \n",
        "    truth = torch.Tensor(0)\n",
        "    device = \"cpu\"\n",
        "    total_loss = 0.\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            model = nn.DataParallel(model)\n",
        "    with torch.no_grad():\n",
        "        for i, (data,targets) in enumerate(data_loader):\n",
        "            if i == 0:\n",
        "                enc_in = data\n",
        "                dec_in = targets\n",
        "                test_rollout = targets\n",
        "            else:\n",
        "                enc_in = test_rollout[:,-window_size:,:]\n",
        "                dec_in = torch.zeros([enc_in.shape[0], 1, enc_in.shape[-1]]).float()\n",
        "                dec_in = torch.cat([enc_in[:,:(window_size-1),:], dec_in], dim=1).float()\n",
        "                #dec_in = enc_in[:,:(window_size-1),:]\n",
        "            enc_in, dec_in, targets = enc_in.to(device), dec_in.to(device), targets.to(device)\n",
        "            output = model(enc_in, dec_in)\n",
        "\n",
        "            total_loss += criterion(output[:,-1:,:], targets[:,-1:,:]).detach().cpu().numpy()\n",
        "            test_rollout = torch.cat([test_rollout,output[:,-1:,:].detach().cpu()],dim = 1)\n",
        "            test_result = torch.cat((test_result, output[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "            truth = torch.cat((truth, targets[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "    return total_loss\n",
        "\n",
        "def predict_model(model, test_loader, window_size, epoch, plot=True):\n",
        "    model.eval()\n",
        "    test_rollout = torch.Tensor(0)   \n",
        "    test_result = torch.Tensor(0)  \n",
        "    truth = torch.Tensor(0)\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            model = nn.DataParallel(model)\n",
        "    with torch.no_grad():\n",
        "        for i, (data,targets) in enumerate(test_loader):\n",
        "            if i == 0:\n",
        "                enc_in = data\n",
        "                dec_in = targets\n",
        "                test_rollout = targets\n",
        "            else:\n",
        "                enc_in = test_rollout[:,-window_size:,:]\n",
        "                dec_in = torch.zeros([enc_in.shape[0], 1, enc_in.shape[-1]]).float()\n",
        "                dec_in = torch.cat([enc_in[:,:(window_size-1),:], dec_in], dim=1).float()\n",
        "                #dec_in = enc_in[:,:(window_size-1),:]\n",
        "            enc_in, dec_in, targets = enc_in.to(device), dec_in.to(device), targets.to(device)\n",
        "            output = model(enc_in, dec_in)\n",
        "\n",
        "            test_rollout = torch.cat([test_rollout,output[:,-1:,:].detach().cpu()],dim = 1)\n",
        "            test_result = torch.cat((test_result, output[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "            truth = torch.cat((truth, targets[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "            \n",
        "    if plot==True:\n",
        "        fig, ax = plt.subplots(nrows =1, ncols=1, figsize=(20,10))\n",
        "        ax.plot(test_result,label='forecast')\n",
        "        ax.plot(truth,label = 'truth')\n",
        "        ax.plot(test_result-truth,ls='--',label='residual')\n",
        "        #ax.grid(True, which='both')\n",
        "        ax.axhline(y=0)\n",
        "        ax.legend(loc=\"upper right\")\n",
        "        fig.savefig(root_dir+f'/figs/informer_epoch{epoch}_pred.png')\n",
        "        plt.close(fig)\n",
        "\n",
        "class early_stopping():\n",
        "    def __init__(self, patience=5, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.early_stop = False\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.best_model = None\n",
        "    \n",
        "    def __call__(self, model, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss < self.best_loss-self.delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            self.best_model = model\n",
        "            torch.save(model, 'best_inf.pth')\n",
        "            print(f'Saving best model')\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter == self.patience:\n",
        "                self.early_stop = True\n",
        "                print('Early stopping')\n",
        "            print(f'----Current loss {val_loss} higher than best loss {self.best_loss}, early stop counter {self.counter}----')\n",
        "    \n",
        "  \n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--requires_training\", default=False, action=\"store_true\")\n",
        "    parser.add_argument(\"--use_pre_trained\", default=False, action=\"store_true\")\n",
        "    parser.add_argument(\"--use_nasa_test_range\", default=False, action=\"store_true\")\n",
        "    parser.add_argument(\"--pre_trained_file_name\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    requires_training = args.requires_training\n",
        "    use_pre_trained = args.use_pre_trained\n",
        "    pre_trained_file_name = args.pre_trained_file_name\n",
        "    use_nasa_test_range = args.use_nasa_test_range\n",
        "\n",
        "    torch.cuda.manual_seed(1008)\n",
        "    torch.cuda.manual_seed_all(1008)  \n",
        "    torch.manual_seed(1008)\n",
        "\n",
        "    root_dir = '' #specify where results will be saved\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    sns.set_palette(['#57068c','#E31212','#01AD86'])\n",
        "    print('pytorch version: ', torch.__version__)\n",
        "    #test\n",
        "    # best_config = {'d_model': 216, 'n_heads': 2, 'e_layers': 3, 'd_layers': 3, 'd_ff': 1024, 'window_size': 192, 'dropout': 0.2, 'lr': 0.0001, 'optim_step': 5, 'lr_decay': 0.9, 'factor': 9, 'batch_size': 128}\n",
        "    #future\n",
        "    best_config = {'d_model': 512, 'n_heads': 4, 'e_layers': 2, 'd_layers': 4, 'd_ff': 512, 'window_size': 192, 'dropout': 0.2, 'lr': 0.0001, 'optim_step': 10, 'lr_decay': 0.75, 'factor': 9, 'batch_size': 128}\n",
        "\n",
        "    train_proportion = 0.7\n",
        "    test_proportion = 0 #test_size is fixed to same as NASA's range and train+val will fill out the rest of the time points if use_nasa_test_range = True.\n",
        "    val_proportion = 0.3\n",
        "    \n",
        "    print(f'Config: {best_config}')\n",
        "\n",
        "    lr = best_config['lr']\n",
        "    optim_step = best_config['optim_step']\n",
        "    lr_decay = best_config['lr_decay']\n",
        "    window_size = best_config['window_size']\n",
        "    batch_size = best_config['batch_size']\n",
        "    enc_channel_in = 1\n",
        "    dec_channel_in = 1\n",
        "    channel_out = 1\n",
        "    seq_len = best_config['window_size']\n",
        "    label_len = best_config['window_size']-1\n",
        "    out_len = 1 #best_config['window_size']\n",
        "    factor = best_config['factor']\n",
        "    d_model = best_config['d_model']\n",
        "    n_heads = best_config['n_heads']\n",
        "    e_layers = best_config['e_layers']\n",
        "    d_layers = best_config['d_layers']\n",
        "    d_ff = best_config['d_ff']\n",
        "    dropout = best_config['dropout']\n",
        "\n",
        "    train_val_loader, train_loader, val_loader, test_loader,scaler = get_data_loaders(train_proportion, test_proportion, val_proportion,\\\n",
        "            window_size=window_size, pred_size =1, batch_size=batch_size, num_workers = 1, pin_memory = True, test_mode = True, use_nasa_test_range=use_nasa_test_range)\n",
        "   \n",
        "    if requires_training:\n",
        "        if use_pre_trained:\n",
        "            model = torch.load(pre_trained_file_name)\n",
        "        else:\n",
        "            model = Informer(enc_channel_in, dec_channel_in, channel_out, seq_len, label_len, out_len,\n",
        "                        factor, d_model, n_heads, e_layers, d_layers, d_ff,\n",
        "                        dropout, attn='prob', embed='fixed', freq='m', activation='gelu',\n",
        "                        output_attention = False, distil=True,\n",
        "                        device=torch.device('cuda:0'))\n",
        "        device = \"cpu\"\n",
        "        if torch.cuda.is_available():\n",
        "            device = \"cuda:0\"\n",
        "            if torch.cuda.device_count() > 1:\n",
        "                model = nn.DataParallel(model)\n",
        "        print('Using device: ',device)\n",
        "        model.to(device)\n",
        "\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, optim_step, gamma=lr_decay)\n",
        "\n",
        "        epochs = 200\n",
        "        train_losses = []\n",
        "        test_losses = []\n",
        "        tolerance = 10\n",
        "        best_test_loss = float('inf')\n",
        "        Early_Stopping = early_stopping(patience=20)\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            model.train()\n",
        "            total_loss = 0.\n",
        "            \n",
        "            for i,(data, targets) in enumerate(train_val_loader):\n",
        "\n",
        "\n",
        "                data, targets = data.to(device), targets.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                output, truth = process_one_batch(data,targets)\n",
        "                loss = criterion(output[:,-1,:], targets[:,-1,:])\n",
        "                total_loss += loss.item()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "\n",
        "            if (epoch%10 == 0) & (use_nasa_test_range != 'non_nasa_no_test'):\n",
        "                print(f'Saving prediction for epoch {epoch}')\n",
        "                predict_model(model, test_loader, window_size, epoch, plot=True)    \n",
        "\n",
        "\n",
        "            train_losses.append(total_loss*batch_size/len(train_val_loader.dataset))\n",
        "            test_loss = evaluate(model, test_loader, criterion, scaler)\n",
        "            test_losses.append(test_loss/len(test_loader.dataset))\n",
        "\n",
        "\n",
        "            if epoch==1: ###DEBUG\n",
        "                print(f'Total of {len(train_val_loader.dataset)} samples in training set and {len(test_loader.dataset)} samples in test set',flush=True)\n",
        "\n",
        "\n",
        "            print(f'Epoch: {epoch}, train_loss: {total_loss*batch_size/len(train_val_loader.dataset)}, test_loss: {test_loss/len(test_loader.dataset)}, lr: {scheduler.get_last_lr()}',flush=True)\n",
        "\n",
        "\n",
        "            Early_Stopping(model, test_loss/len(test_loader))\n",
        "            if Early_Stopping.early_stop:\n",
        "                break\n",
        "\n",
        "            if epoch%1== 0:\n",
        "                scheduler.step()\n",
        "\n",
        "\n",
        "    ## Plot losses                \n",
        "        xs = np.arange(len(train_losses))\n",
        "        fig, ax = plt.subplots(nrows =1, ncols=1, figsize=(20,10))\n",
        "        ax.plot(xs,train_losses)\n",
        "        fig.savefig(root_dir + '/figs/informer_train_loss.png')\n",
        "        plt.close(fig)\n",
        "        fig, ax = plt.subplots(nrows =1, ncols=1, figsize=(20,10))\n",
        "        ax.plot(xs,test_losses)\n",
        "        fig.savefig(root_dir + '/figs/informer_test_loss.png')\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "### Predict\n",
        "    if not requires_training:\n",
        "        model = torch.load(pre_trained_file_name)\n",
        "    else:\n",
        "        model = torch.load('best_inf.pth')\n",
        "    model.eval()\n",
        "    test_rollout = torch.Tensor(0)   \n",
        "    test_result = torch.Tensor(0)  \n",
        "    truth = torch.Tensor(0)\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            model = nn.DataParallel(model)\n",
        "    with torch.no_grad():\n",
        "        for i, (data,targets) in enumerate(test_loader):\n",
        "            if i == 0:\n",
        "                enc_in = data\n",
        "                dec_in = targets\n",
        "                test_rollout = targets\n",
        "            else:\n",
        "                enc_in = test_rollout[:,-window_size:,:]\n",
        "                dec_in = torch.zeros([enc_in.shape[0], 1, enc_in.shape[-1]]).float()\n",
        "                dec_in = torch.cat([enc_in[:,:(window_size-1),:], dec_in], dim=1).float()\n",
        "                \n",
        "            enc_in, dec_in, targets = enc_in.to(device), dec_in.to(device), targets.to(device)\n",
        "            output = model(enc_in, dec_in)\n",
        "\n",
        "            test_rollout = torch.cat([test_rollout,output[:,-1:,:].detach().cpu()],dim = 1)\n",
        "            test_result = torch.cat((test_result, output[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "            truth = torch.cat((truth, targets[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "    ### Save forecast on val set to train xgboost\n",
        "    val_rollout = torch.Tensor(0)   \n",
        "    val_result = torch.Tensor(0)  \n",
        "    val_truth = torch.Tensor(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data,targets) in enumerate(val_loader):\n",
        "            if i == 0:\n",
        "                enc_in = data\n",
        "                dec_in = targets\n",
        "                val_rollout = targets\n",
        "            else:\n",
        "                enc_in = val_rollout[:,-window_size:,:]\n",
        "                dec_in = torch.zeros([enc_in.shape[0], 1, enc_in.shape[-1]]).float()\n",
        "                dec_in = torch.cat([enc_in[:,:(window_size-1),:], dec_in], dim=1).float()\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            output, _ = process_one_batch(data,targets)\n",
        "\n",
        "            val_rollout = torch.cat([val_rollout,output[:,-1:,:].detach().cpu()],dim = 1)\n",
        "            val_result = torch.cat((val_result, output[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "            val_truth = torch.cat((val_truth, targets[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "            \n",
        "    train_rollout = torch.Tensor(0)   \n",
        "    train_result = torch.Tensor(0)  \n",
        "    train_truth = torch.Tensor(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data,targets) in enumerate(train_loader):\n",
        "            if i == 0:\n",
        "                enc_in = data\n",
        "                dec_in = targets\n",
        "                train_rollout = targets\n",
        "            else:\n",
        "                enc_in = train_rollout[:,-window_size:,:]\n",
        "                dec_in = torch.zeros([enc_in.shape[0], 1, enc_in.shape[-1]]).float()\n",
        "                dec_in = torch.cat([enc_in[:,:(window_size-1),:], dec_in], dim=1).float()\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            output, _ = process_one_batch(data,targets)\n",
        "\n",
        "            train_rollout = torch.cat([train_rollout,output[:,-1:,:].detach().cpu()],dim = 1)\n",
        "            train_result = torch.cat((train_result, output[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "            train_truth = torch.cat((train_truth, targets[:,-1,:].view(-1).detach().cpu()), 0)\n",
        "\n",
        "### Check MSE, MAE\n",
        "    val_result = val_result.numpy()\n",
        "    val_result = val_result.reshape(-1, 1)\n",
        "    val_result = scaler.inverse_transform(val_result)\n",
        "\n",
        "    test_result = test_result.numpy()\n",
        "    test_result = test_result.reshape(-1,1)\n",
        "    test_result = scaler.inverse_transform(test_result)\n",
        "    train_result = train_result.numpy()\n",
        "    train_result = train_result.reshape(-1,1)\n",
        "    train_result = scaler.inverse_transform(train_result)\n",
        "    truth = truth.numpy()\n",
        "    truth = truth.reshape(-1,1)\n",
        "    truth = scaler.inverse_transform(truth)\n",
        "    train_truth = train_truth.numpy()\n",
        "    train_truth = train_truth.reshape(-1,1)\n",
        "    train_truth = scaler.inverse_transform(train_truth)\n",
        "    val_truth = val_truth.numpy()\n",
        "    val_truth = val_truth.reshape(-1,1)\n",
        "    val_truth = scaler.inverse_transform(val_truth)\n",
        "\n",
        "    RMSE = mean_squared_error(truth, test_result)**0.5\n",
        "    MAE = mean_absolute_error(truth, test_result)\n",
        "    RMSE_first_window = mean_squared_error(truth[:window_size+1], test_result[:window_size+1])**0.5\n",
        "    MAE_first_window = mean_absolute_error(truth[:window_size+1], test_result[:window_size+1])\n",
        "    RMSE_after_first_window = mean_squared_error(truth[window_size:], test_result[window_size:])**0.5\n",
        "    MAE_after_first_window = mean_absolute_error(truth[window_size:], test_result[window_size:])\n",
        "    print(f'RMSE: {RMSE}, MAE: {MAE} \\n RMSE_first_window: {RMSE_first_window}, MAE_first_window: {MAE_first_window} \\n RMSE_after_first_window: {RMSE_after_first_window}, MAE_after_first_window: {MAE_after_first_window}')\n",
        "\n",
        "    fig, ax = plt.subplots(nrows =1, ncols=1, figsize=(20,10))\n",
        "    ax.plot(test_result,label='forecast')\n",
        "    ax.plot(truth,label = 'truth')\n",
        "    ax.plot(test_result-truth,ls='--',label='residual')\n",
        "    #ax.grid(True, which='both')\n",
        "    ax.axhline(y=0)\n",
        "    ax.legend(loc=\"upper right\")\n",
        "    #fig.savefig(root_dir + '/figs/informer_inversed_pred.png')\n",
        "\n",
        "    fig, ax = plt.subplots(nrows =1, ncols=1, figsize=(20,10))\n",
        "    ax.plot(val_result,label='forecast')\n",
        "    ax.plot(val_truth,label = 'truth')\n",
        "    ax.plot(val_result-val_truth,ls='--',label='residual')\n",
        "    ax.axhline(y=0)\n",
        "    ax.legend(loc=\"upper right\")\n",
        "    #fig.savefig(root_dir + '/figs/informer_val_inverse_prediction.png')\n",
        "\n",
        "    fig, ax = plt.subplots(nrows =1, ncols=1, figsize=(20,10))\n",
        "    ax.plot(train_result,label='forecast')\n",
        "    ax.plot(train_truth,label = 'truth')\n",
        "    ax.plot(train_result-train_truth,ls='--',label='residual')\n",
        "    ax.axhline(y=0)\n",
        "    ax.legend(loc=\"upper right\")\n",
        "    #fig.savefig(root_dir + '/figs/informer_train_inverse_prediction.png')\n",
        "\n",
        "    plt.close(fig)\n",
        "### Save model result\n",
        "\n",
        "\n",
        "    # train_result_df = pd.DataFrame(train_result)\n",
        "    # train_result_df.to_csv(root_dir + '/informer_train_prediction.csv')\n",
        "    # train_truth_df = pd.DataFrame(train_truth)\n",
        "    # train_truth_df.to_csv(root_dir + '/sunspot_train_truth.csv')\n",
        "\n",
        "    # val_result_df = pd.DataFrame(val_result)\n",
        "    # val_result_df.to_csv(root_dir + '/informer_val_prediction.csv')\n",
        "    # val_truth_df = pd.DataFrame(val_truth)\n",
        "    # val_truth_df.to_csv(root_dir + '/sunspot_val_truth.csv')\n",
        "\n",
        "    # test_result_df = pd.DataFrame(test_result)\n",
        "    # test_result_df.to_csv(root_dir + '/informer_prediction.csv')\n",
        "    # truth_df = pd.DataFrame(truth)\n",
        "    # truth_df.to_csv(root_dir + '/sunspot_truth.csv')"
      ],
      "metadata": {
        "id": "2KirvZxUGbeI"
      }
    }
  ]
}